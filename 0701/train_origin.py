import os
import pandas as pd
from PIL import Image
import torch
from torch import nn
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms, models
from tqdm import tqdm
import torch.nn.functional as F
from sklearn.model_selection import train_test_split
import numpy as np

# ============= í”„ë¡œì íŠ¸ ê²½ë¡œ ì„¤ì • =============
PROJECT_ROOT = "C:/planttest0/"  # ì‹¤ì œ ê²½ë¡œë¡œ ë³€ê²½
CSV_PATH = os.path.join(PROJECT_ROOT, "0701", "dataset8_updated.csv")  # ì—…ë°ì´íŠ¸ëœ CSV ì‚¬ìš©
IMG_DIR = "C:/planttest0/TS/TS_3.8/TS_3.8"  # ì´ë¯¸ì§€ í´ë” ê²½ë¡œ

BATCH_SIZE = 16
EPOCHS = 5
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
TOTAL_GROWTH_DAYS = 30

# ============= CSV ë°ì´í„° ë¶„ì„ ë° ì „ì²˜ë¦¬ =============
def analyze_csv_data(csv_path):
    """CSV ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  ì „ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜"""
    print("ðŸ“Š CSV ë°ì´í„° ë¶„ì„ ì¤‘...")
    
    # CSV íŒŒì¼ ë¡œë“œ
    df = pd.read_csv(csv_path)
    print(f"ðŸ“ˆ ì´ ë°ì´í„° ìˆ˜: {len(df)}ê°œ")
    print(f"ðŸ“‹ ì»¬ëŸ¼ë“¤: {list(df.columns)}")
    
    # ê¸°ë³¸ í†µê³„ ì •ë³´
    print("\nðŸ“Š ë°ì´í„° ìš”ì•½:")
    print(df.describe())
    
    # ê²°ì¸¡ê°’ í™•ì¸
    missing_data = df.isnull().sum()
    if missing_data.any():
        print(f"\nâš ï¸ ê²°ì¸¡ê°’ ë°œê²¬:")
        print(missing_data[missing_data > 0])
    
    # ì´ë¯¸ì§€ íŒŒì¼ ì¡´ìž¬ ì—¬ë¶€ í™•ì¸
    if 'fname' in df.columns:
        missing_images = []
        for idx, fname in enumerate(df['fname']):
            img_path = os.path.join(IMG_DIR, fname)
            if not os.path.exists(img_path):
                missing_images.append(fname)
        
        if missing_images:
            print(f"\nâŒ ì—†ëŠ” ì´ë¯¸ì§€ íŒŒì¼: {len(missing_images)}ê°œ")
            print("ì²˜ìŒ 5ê°œ:", missing_images[:5])
        else:
            print("âœ… ëª¨ë“  ì´ë¯¸ì§€ íŒŒì¼ ì¡´ìž¬ í™•ì¸!")
    
    return df

def preprocess_data(df):
    """ë°ì´í„° ì „ì²˜ë¦¬ ë° ìƒˆë¡œìš´ ì»¬ëŸ¼ ìƒì„±"""
    print("ðŸ”§ ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘...")
    
    # ê²°ì¸¡ê°’ ì²˜ë¦¬
    df = df.dropna()
    
    # ë‚¨ì€ ì¼ìˆ˜ ê³„ì‚°
    df["days_left"] = TOTAL_GROWTH_DAYS - df["estimated_days_elapsed"]
    df["days_left"] = df["days_left"].clip(lower=0)
    
    # ì„±ìž¥ ë‹¨ê³„ ë¶„ë¥˜ (5ë‹¨ê³„)
    growth_stage_map = {
        "ì •ì‹ê¸°": 0,
        "ìƒìœ¡ê¸°": 1,
        "ìˆ˜í™•ê¸°": 2
    }
    df["growth_stage"] = df["growth_stage"].map(growth_stage_map)

    if df["growth_stage"].isnull().any():
        print("âš ï¸ ìƒìœ¡ ë‹¨ê³„ì— ì •ì˜ë˜ì§€ ì•Šì€ ê°’ì´ ìžˆìŠµë‹ˆë‹¤. ì œê±°í•©ë‹ˆë‹¤.")
        df = df.dropna(subset=["growth_stage"])


    # ê±´ê°•ë„ ì ìˆ˜ ê³„ì‚° (ìž„ì‹œ ê³µì‹ - ë‚˜ì¤‘ì— ì‹¤ì œ ë°ì´í„°ë¡œ ê°œì„ )
    # ì„±ìž¥ ì†ë„ì™€ ì˜ˆìƒ í¬ê¸°ë¥¼ ê³ ë ¤í•œ ê±´ê°•ë„
    df["health_score"] = np.clip(
        (df["estimated_days_elapsed"] / 30) * np.random.uniform(0.8, 1.0, len(df)), 
        0, 1
    )
    
    # ì´ìƒê°’ ì œê±°
    Q1 = df["days_left"].quantile(0.25)
    Q3 = df["days_left"].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    
    df = df[(df["days_left"] >= lower_bound) & (df["days_left"] <= upper_bound)]
    
    print(f"âœ… ì „ì²˜ë¦¬ ì™„ë£Œ! ìµœì¢… ë°ì´í„° ìˆ˜: {len(df)}ê°œ")
    print(f"ðŸ“Š ì„±ìž¥ ë‹¨ê³„ ë¶„í¬:")
    print(df["growth_stage"].value_counts().sort_index())
    
    return df

# ============= í–¥ìƒëœ ë°ì´í„°ì…‹ í´ëž˜ìŠ¤ =============
class SmartLettuceDataset(Dataset):
    """CSV ë°ì´í„°ë¥¼ í™œìš©í•œ ìŠ¤ë§ˆíŠ¸ ìƒì¶” ë°ì´í„°ì…‹"""
    
    def __init__(self, dataframe, img_dir, transform=None):
        self.data = dataframe.reset_index(drop=True)
        self.img_dir = img_dir
        self.transform = transform
        
        # ì´ë¯¸ì§€ ì¡´ìž¬ ì—¬ë¶€ ìž¬í™•ì¸
        valid_indices = []
        for idx in range(len(self.data)):
            fname = self.data.iloc[idx]['fname']
            img_path = os.path.join(img_dir, fname)
            if os.path.exists(img_path):
                valid_indices.append(idx)
        
        self.data = self.data.iloc[valid_indices].reset_index(drop=True)
        print(f"ðŸ“· ìœ íš¨í•œ ì´ë¯¸ì§€ê°€ ìžˆëŠ” ë°ì´í„°: {len(self.data)}ê°œ")

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        row = self.data.iloc[idx]
        
        # ì´ë¯¸ì§€ ë¡œë“œ
        img_path = os.path.join(self.img_dir, row["fname"])
        try:
            image = Image.open(img_path).convert("RGB")
        except Exception as e:
            print(f"âš ï¸ ì´ë¯¸ì§€ ë¡œë“œ ì˜¤ë¥˜: {row['fname']}")
            # ê¸°ë³¸ ë…¹ìƒ‰ ì´ë¯¸ì§€ë¡œ ëŒ€ì²´
            image = Image.new('RGB', (224, 224), color=(34, 139, 34))
        
        if self.transform:
            image = self.transform(image)
        
        # ë¼ë²¨ë“¤
        days_left = torch.tensor([row["days_left"]], dtype=torch.float32)
        growth_stage = torch.tensor(row["growth_stage"], dtype=torch.long)
        health_score = torch.tensor([row["health_score"]], dtype=torch.float32)
        
        return image, days_left, growth_stage, health_score

# ============= ë°ì´í„° ì¦ê°• =============
def get_transforms():
    """ë†ì—… í™˜ê²½ì— íŠ¹í™”ëœ ë°ì´í„° ì¦ê°•"""
    
    train_transform = transforms.Compose([
        transforms.Resize((256, 256)),
        transforms.RandomCrop(224, padding=4),
        transforms.RandomHorizontalFlip(0.5),
        
        # ì‹¤ì™¸ ë†ìž¥ í™˜ê²½ ì‹œë®¬ë ˆì´ì…˜
        transforms.ColorJitter(
            brightness=0.3,    # í–‡ë¹› ë³€í™”
            contrast=0.3,      # ê·¸ë¦¼ìž íš¨ê³¼
            saturation=0.2,    # ê³„ì ˆë³„ ìƒ‰ìƒ ë³€í™”
            hue=0.1           # ì•½ê°„ì˜ ìƒ‰ì¡° ë³€í™”
        ),
        
        # ì¹´ë©”ë¼ ê°ë„ ë³€í™”
        transforms.RandomRotation(15),
        
        # ë°”ëžŒì— ì˜í•œ í”ë“¤ë¦¼ íš¨ê³¼
        transforms.RandomApply([
            transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 1.0))
        ], p=0.1),
        
        transforms.ToTensor(),
        transforms.Normalize(
            mean=[0.485, 0.456, 0.406], 
            std=[0.229, 0.224, 0.225]
        )
    ])
    
    val_transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(
            mean=[0.485, 0.456, 0.406], 
            std=[0.229, 0.224, 0.225]
        )
    ])
    
    return train_transform, val_transform

# ============= ë¼ì¦ˆë² ë¦¬íŒŒì´ ìµœì í™” ëª¨ë¸ =============
class RaspberryPiLettuceModel(nn.Module):
    """ë¼ì¦ˆë² ë¦¬íŒŒì´ì— ìµœì í™”ëœ ìƒì¶” ì˜ˆì¸¡ ëª¨ë¸"""
    
    def __init__(self, num_stages=5):
        super().__init__()
        
        # MobileNetV3 Small - ë¼ì¦ˆë² ë¦¬íŒŒì´ ìµœì í™”
        self.backbone = models.mobilenet_v3_small(weights='DEFAULT')
        
        # íŠ¹ì§• ì¶”ì¶œ ë¶€ë¶„ë§Œ ì‚¬ìš©
        self.features = self.backbone.features
        self.avgpool = self.backbone.avgpool
        
        # ë¶„ë¥˜ê¸° ë¶€ë¶„ êµì²´
        self.classifier = nn.Sequential(
            nn.Linear(576, 256),  # MobileNetV3-small ì¶œë ¥ í¬ê¸°
            nn.Hardswish(),       # MobileNetì—ì„œ ì‚¬ìš©í•˜ëŠ” í™œì„±í™” í•¨ìˆ˜
            nn.Dropout(0.2),
            nn.Linear(256, 128),
            nn.Hardswish(),
            nn.Dropout(0.1)
        )
        
        # ë©€í‹°íƒœìŠ¤í¬ í—¤ë“œ
        self.days_head = nn.Linear(128, 1)                    # ë‚¨ì€ ì¼ìˆ˜
        self.stage_head = nn.Linear(128, num_stages)          # ì„±ìž¥ ë‹¨ê³„  
        self.health_head = nn.Sequential(                     # ê±´ê°•ë„
            nn.Linear(128, 1),
            nn.Sigmoid()
        )

    def forward(self, x):
        # íŠ¹ì§• ì¶”ì¶œ
        x = self.features(x)
        x = self.avgpool(x)
        x = torch.flatten(x, 1)
        
        # ê³µí†µ íŠ¹ì§•
        features = self.classifier(x)
        
        # ê° íƒœìŠ¤í¬ë³„ ì˜ˆì¸¡
        days_left = self.days_head(features)
        growth_stage = self.stage_head(features)
        health_score = self.health_head(features)
        
        return days_left, growth_stage, health_score

# ============= í•™ìŠµ ë° ê²€ì¦ í•¨ìˆ˜ =============
def train_with_validation():
    """ê²€ì¦ ì„¸íŠ¸ë¥¼ í¬í•¨í•œ í•™ìŠµ"""
    
    print("ðŸš€ CSV ê¸°ë°˜ ìƒì¶” ì˜ˆì¸¡ ëª¨ë¸ í•™ìŠµ ì‹œìž‘!")
    
    # 1. ë°ì´í„° ë¡œë“œ ë° ë¶„ì„
    df = analyze_csv_data(CSV_PATH)
    df = preprocess_data(df)
    
    # 2. í•™ìŠµ/ê²€ì¦ ë°ì´í„° ë¶„í• 
    train_df, val_df = train_test_split(
        df, test_size=0.2, random_state=42, 
        stratify=df['growth_stage']  # ì„±ìž¥ ë‹¨ê³„ë³„ ë¹„ìœ¨ ìœ ì§€
    )
    
    print(f"ðŸ“š í•™ìŠµ ë°ì´í„°: {len(train_df)}ê°œ")
    print(f"ðŸ” ê²€ì¦ ë°ì´í„°: {len(val_df)}ê°œ")
    
    # 3. ë°ì´í„°ì…‹ ë° ë¡œë” ìƒì„±
    train_transform, val_transform = get_transforms()
    
    train_dataset = SmartLettuceDataset(train_df, IMG_DIR, train_transform)
    val_dataset = SmartLettuceDataset(val_df, IMG_DIR, val_transform)
    
    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)
    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)
    
    # 4. ëª¨ë¸ ì´ˆê¸°í™”
    model = RaspberryPiLettuceModel().to(DEVICE)
    
    # íŒŒë¼ë¯¸í„° ìˆ˜ ê³„ì‚°
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    print(f"ðŸ§  ì „ì²´ íŒŒë¼ë¯¸í„°: {total_params:,}")
    print(f"ðŸŽ¯ í•™ìŠµ íŒŒë¼ë¯¸í„°: {trainable_params:,}")
    
    # 5. ì†ì‹¤ í•¨ìˆ˜ ë° ì˜µí‹°ë§ˆì´ì €
    criterion_days = nn.MSELoss()
    criterion_stage = nn.CrossEntropyLoss()
    criterion_health = nn.L1Loss()
    
    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)
    
    # 6. í•™ìŠµ ê¸°ë¡
    train_losses = []
    val_losses = []
    best_val_loss = float('inf')
    
    # 7. í•™ìŠµ ë£¨í”„
    for epoch in range(EPOCHS):
        # í•™ìŠµ
        model.train()
        train_loss = 0
        train_acc = 0
        
        pbar = tqdm(train_loader, desc=f"ðŸŒ± í•™ìŠµ {epoch+1}/{EPOCHS}")
        for images, days_true, stages_true, health_true in pbar:
            images = images.to(DEVICE)
            days_true = days_true.to(DEVICE)
            stages_true = stages_true.to(DEVICE)
            health_true = health_true.to(DEVICE)
            
            # ìˆœì „íŒŒ
            days_pred, stages_pred, health_pred = model(images)
            
            # ì†ì‹¤ ê³„ì‚°
            loss_days = criterion_days(days_pred, days_true)
            loss_stage = criterion_stage(stages_pred, stages_true)
            loss_health = criterion_health(health_pred, health_true)
            
            total_loss = 0.5 * loss_days + 0.3 * loss_stage + 0.2 * loss_health
            
            # ì—­ì „íŒŒ
            optimizer.zero_grad()
            total_loss.backward()
            optimizer.step()
            
            # í†µê³„
            train_loss += total_loss.item()
            _, predicted = torch.max(stages_pred.data, 1)
            train_acc += (predicted == stages_true).sum().item() / len(stages_true)
            
            pbar.set_postfix({
                'Loss': f"{train_loss/(len(pbar)):.3f}",
                'Acc': f"{train_acc/(len(pbar)):.3f}"
            })
        
        # ê²€ì¦
        model.eval()
        val_loss = 0
        val_acc = 0
        
        with torch.no_grad():
            for images, days_true, stages_true, health_true in val_loader:
                images = images.to(DEVICE)
                days_true = days_true.to(DEVICE)
                stages_true = stages_true.to(DEVICE)
                health_true = health_true.to(DEVICE)
                
                days_pred, stages_pred, health_pred = model(images)
                
                loss_days = criterion_days(days_pred, days_true)
                loss_stage = criterion_stage(stages_pred, stages_true)
                loss_health = criterion_health(health_pred, health_true)
                
                total_loss = 0.5 * loss_days + 0.3 * loss_stage + 0.2 * loss_health
                val_loss += total_loss.item()
                
                _, predicted = torch.max(stages_pred.data, 1)
                val_acc += (predicted == stages_true).sum().item() / len(stages_true)
        
        # í‰ê·  ê³„ì‚°
        train_loss /= len(train_loader)
        val_loss /= len(val_loader)
        train_acc /= len(train_loader)
        val_acc /= len(val_loader)
        
        train_losses.append(train_loss)
        val_losses.append(val_loss)
        
        # ìŠ¤ì¼€ì¤„ëŸ¬ ì—…ë°ì´íŠ¸
        scheduler.step()
        
        # ê²°ê³¼ ì¶œë ¥
        print(f"\nðŸ“Š Epoch {epoch+1} ê²°ê³¼:")
        print(f"   í•™ìŠµ - ì†ì‹¤: {train_loss:.4f}, ì •í™•ë„: {train_acc:.3f}")
        print(f"   ê²€ì¦ - ì†ì‹¤: {val_loss:.4f}, ì •í™•ë„: {val_acc:.3f}")
        print(f"   í•™ìŠµë¥ : {optimizer.param_groups[0]['lr']:.6f}")
        
        # ìµœê³  ëª¨ë¸ ì €ìž¥
        if val_loss < best_val_loss:
            best_val_loss = val_loss
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'train_loss': train_loss,
                'val_loss': val_loss,
                'train_acc': train_acc,
                'val_acc': val_acc
            }, 'best_lettuce_model.pth')
            print("   â­ ìƒˆë¡œìš´ ìµœê³  ëª¨ë¸ ì €ìž¥!")
    
    print("âœ… í•™ìŠµ ì™„ë£Œ!")
    return model

# ============= ì‹¤ì‹œê°„ ì˜ˆì¸¡ í•¨ìˆ˜ =============
def predict_from_raspberry_pi(model_path, image_path):
    """ë¼ì¦ˆë² ë¦¬íŒŒì´ì—ì„œ ì‹¤ì‹œê°„ ì˜ˆì¸¡"""
    
    # ëª¨ë¸ ë¡œë“œ
    model = RaspberryPiLettuceModel()
    checkpoint = torch.load(model_path, map_location='cpu')
    model.load_state_dict(checkpoint['model_state_dict'])
    model.eval()
    
    # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
    _, val_transform = get_transforms()
    image = Image.open(image_path).convert("RGB")
    image_tensor = val_transform(image).unsqueeze(0)
    
    # ì˜ˆì¸¡
    with torch.no_grad():
        days_pred, stage_pred, health_pred = model(image_tensor)
        
        # ê²°ê³¼ í•´ì„
        days_left = max(0, round(days_pred.item(), 1))
        stage_probs = F.softmax(stage_pred, dim=1)
        stage_idx = torch.argmax(stage_probs, dim=1).item()
        stage_conf = stage_probs[0][stage_idx].item() * 100
        health_score = health_pred.item() * 100
        
        stage_names = ["ðŸŒ± ìƒˆì‹¹", "ðŸŒ¿ ì´ˆê¸°", "ðŸ¥¬ ì¤‘ê¸°", "ðŸƒ í›„ê¸°", "ðŸŽ¯ ìˆ˜í™•"]
        
        result = {
            "ìˆ˜í™•_ì˜ˆìƒì¼": f"{days_left}ì¼ í›„",
            "í˜„ìž¬_ë‹¨ê³„": stage_names[stage_idx],
            "ë‹¨ê³„_ì‹ ë¢°ë„": f"{stage_conf:.1f}%",
            "ê±´ê°•ë„": f"{health_score:.1f}ì ",
            "ì¶”ì²œ_ì¡°ì¹˜": get_recommendation(days_left, stage_idx, health_score)
        }
        
        return result

def get_recommendation(days_left, stage_idx, health_score):
    """ìƒí™©ë³„ ì¶”ì²œ ì¡°ì¹˜"""
    
    if health_score < 60:
        return "âš ï¸ ê±´ê°•ë„ê°€ ë‚®ìŠµë‹ˆë‹¤. ì˜ì–‘ë¶„ ê³µê¸‰ì„ í™•ì¸í•˜ì„¸ìš”."
    elif stage_idx >= 4:
        return "ðŸŽ‰ ìˆ˜í™• ì‹œê¸°ìž…ë‹ˆë‹¤!"
    elif days_left <= 3:
        return "ðŸ”” ê³§ ìˆ˜í™• ê°€ëŠ¥í•©ë‹ˆë‹¤. ì¤€ë¹„í•˜ì„¸ìš”!"
    elif days_left <= 7:
        return "â° 1ì£¼ì¼ ë‚´ ìˆ˜í™• ì˜ˆì •ìž…ë‹ˆë‹¤."
    else:
        return "âœ… ê±´ê°•í•˜ê²Œ ìžë¼ê³  ìžˆìŠµë‹ˆë‹¤."

# ============= ë©”ì¸ ì‹¤í–‰ =============
if __name__ == "__main__":
    print("ðŸ¥¬ CSV ê¸°ë°˜ ìŠ¤ë§ˆíŠ¸ ìƒì¶” ì˜ˆì¸¡ ì‹œìŠ¤í…œ")
    print("=" * 50)
    
    # CSV íŒŒì¼ ê²½ë¡œ í™•ì¸
    if not os.path.exists(CSV_PATH):
        print(f"âŒ CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {CSV_PATH}")
        print("ðŸ“ ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”!")
    else:
        print(f"âœ… CSV íŒŒì¼ ë°œê²¬: {CSV_PATH}")
        
        # í•™ìŠµ ì‹¤í–‰
        model = train_with_validation()
        
        print("\nðŸŽ‰ ëª¨ë“  ê³¼ì • ì™„ë£Œ!")
        print("ðŸ“ ìƒì„±ëœ íŒŒì¼: best_lettuce_model.pth")
        
        # í…ŒìŠ¤íŠ¸ ì˜ˆì¸¡ ì˜ˆì‹œ
        # result = predict_from_raspberry_pi('best_lettuce_model.pth', 'test_image.jpg')
        # print(f"\nðŸ” ì˜ˆì¸¡ ê²°ê³¼: {result}")
